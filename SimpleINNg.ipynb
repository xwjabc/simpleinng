{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleINNg: Simplified Version of Long Jin's INNg\n",
    "\n",
    "This notebook implements a simplified version of Long Jin's INNg training code, that is, the code under `unsupervised` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:12.083973Z",
     "start_time": "2017-08-31T00:09:12.079482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__version__ = 'v1'\n",
    "__author__ = 'Weijian Xu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Libraries and Functions\n",
    "\n",
    "This section imports or creates a series of functions to support model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Library\n",
    "\n",
    "This section imports all needed libraries. All libraries are either built-in or from PyPI. You may need to use `pip` to install missing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.544254Z",
     "start_time": "2017-08-31T00:09:12.086932Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import PIL\n",
    "import time\n",
    "import copy\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Display the versions for libraries. In my environment, they are\n",
    "#     Python version: 2.7.13 |Anaconda custom (64-bit)| (default, Dec 20 2016, 23:09:15) \n",
    "#     [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
    "#     SciPy version: 0.19.0\n",
    "#     NumPy version: 1.12.1\n",
    "#     TensorFlow version: 1.2.0\n",
    "#     Scikit-learn version: 0.18.1\n",
    "#     PIL version: 3.4.2\n",
    "print('Python version: {}'.format(sys.version))\n",
    "print('SciPy version: {}'.format(scipy.__version__))\n",
    "print('NumPy version: {}'.format(np.__version__))\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('Scikit-learn version: {}'.format(sklearn.__version__))\n",
    "print('PIL version: {}'.format(PIL.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Utility Functions\n",
    "\n",
    "This section contains utility functions, including directory creation and traverse, image generating, reading, saving, merging, normalizing, unnormalizing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.551664Z",
     "start_time": "2017-08-31T00:09:13.545809Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_number_on_image(image,\n",
    "                         number,\n",
    "                         text_format = '{:.3f}'):\n",
    "    '''\n",
    "    Draw a blue number on given image array.\n",
    "        image:       Image array.\n",
    "        number:      Number to draw.\n",
    "        text_format: Format of text including the number.\n",
    "    Return the modified image array.\n",
    "    '''\n",
    "    PIL_image = PIL.Image.fromarray(image)\n",
    "    draw = PIL.ImageDraw.Draw(PIL_image)\n",
    "    text = text_format.format(number)\n",
    "    draw.text(xy = (0, 0), text = text, fill = (0, 0, 255, 255))\n",
    "    return np.array(PIL_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.565033Z",
     "start_time": "2017-08-31T00:09:13.553067Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def log(log_file_path, string):\n",
    "    '''\n",
    "    Write one line of log into screen and file.\n",
    "        log_file_path: Path of log file.\n",
    "        string:        String to write in log file.\n",
    "    '''\n",
    "    with open(log_file_path, 'a+') as f:\n",
    "        f.write(string + '\\n')\n",
    "        f.flush()\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.574493Z",
     "start_time": "2017-08-31T00:09:13.566428Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mkdir_if_not_exists(path):\n",
    "    '''\n",
    "    Create directory if it does not exist.\n",
    "        path:           Path of directory.\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.582274Z",
     "start_time": "2017-08-31T00:09:13.575850Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_images_path_in_directory(path):\n",
    "    '''\n",
    "    Get path of all images recursively in directory filtered by extension list.\n",
    "        path: Path of directory contains images.\n",
    "    Return path of images in selected directory.\n",
    "    '''\n",
    "    images_path_in_directory = []\n",
    "    image_extensions = ['.png', '.jpg']\n",
    "    \n",
    "    for root_path, directory_names, file_names in os.walk(path):\n",
    "        for file_name in file_names:\n",
    "            lower_file_name = file_name.lower()\n",
    "            if any(map(lambda image_extension: \n",
    "                       lower_file_name.endswith(image_extension), \n",
    "                       image_extensions)):\n",
    "                images_path_in_directory.append(os.path.join(root_path, file_name))\n",
    "\n",
    "    return images_path_in_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.591630Z",
     "start_time": "2017-08-31T00:09:13.583525Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_unnormalized_image(image, path):\n",
    "    '''\n",
    "    Save one image.\n",
    "        image: Unnormalized images array. The count of images \n",
    "               should match the size and the intensity values range\n",
    "               from 0 to 255. Format: [height, width, channels]\n",
    "        path:  Path of merged image.\n",
    "    '''\n",
    "    # Attention: Here we should not use the following way to save image.\n",
    "    #     scipy.misc.imsave(path, image)\n",
    "    # Because it automatically scale the intensity value in image\n",
    "    # from [min(image), max(image)] to [0, 255]. It should be\n",
    "    # the reason behind the issue reported by Kwonjoon Lee, which states \n",
    "    # the intensity value in demo in INNg paper is much near 0 or 255.\n",
    "    scipy.misc.toimage(arr = image, cmin = 0, cmax = 255).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.601531Z",
     "start_time": "2017-08-31T00:09:13.593088Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_unnormalized_images(images, size, path):\n",
    "    '''\n",
    "    Merge multiple unnormalized images into one and save it.\n",
    "        images: Unnormalized images array. The count of images \n",
    "                should match the size and the intensity values range\n",
    "                from 0 to 255. Format: [count, height, width, channels]\n",
    "        size:   Number of images to merge. \n",
    "                Format: (vertical_count, horizontal_count).\n",
    "        path:   Path of merged image.\n",
    "    '''\n",
    "    merged_image = merge(images, size)\n",
    "    # Attention: Here we should not use the following way to save image.\n",
    "    #     scipy.misc.imsave(path, merged_image)\n",
    "    # Because it automatically scale the intensity value in merged_image\n",
    "    # from [min(merged_image), max(merged_image)] to [0, 255]. It should be\n",
    "    # the reason behind the issue reported by Kwonjoon Lee, which states \n",
    "    # the intensity value in demo in INNg paper is much near 0 or 255.\n",
    "    scipy.misc.toimage(arr = merged_image, cmin = 0, cmax = 255).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.611064Z",
     "start_time": "2017-08-31T00:09:13.603225Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_unnormalized_image(path):\n",
    "    '''\n",
    "    Load a RGB image and do not normalize. Each intensity value is from \n",
    "    0 to 255 and then it is converted into 32-bit float.\n",
    "        path: Path of image file.\n",
    "    Return image array.\n",
    "    '''\n",
    "    return scipy.misc.imread(path, mode = 'RGB').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.620844Z",
     "start_time": "2017-08-31T00:09:13.612408Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def merge(images, size):\n",
    "    '''\n",
    "    Merge several images into one.\n",
    "        size: Number of images to merge. \n",
    "              Format: (vertical_count, horizontal_count)\n",
    "    Return merged image array.\n",
    "    '''\n",
    "    count, height, width, channels = images.shape\n",
    "    vertical_count, horizontal_count = size\n",
    "    if not (vertical_count * horizontal_count == count):\n",
    "        raise ValueError(\"Count of images does not match size.\")\n",
    "        \n",
    "    # Merged image looks like\n",
    "    #     [ ][ ][ ]\n",
    "    #     [ ][ ][ ]\n",
    "    #     [ ][ ][ ]\n",
    "    # when size = [3, 3].\n",
    "    merged_image = np.zeros((height * vertical_count, \n",
    "                             width * horizontal_count, \n",
    "                             channels))\n",
    "    for i, image in enumerate(images):\n",
    "        m = i // vertical_count\n",
    "        n = i % vertical_count\n",
    "        merged_image[m * height : (m + 1) * height, \n",
    "                     n * width : (n + 1) * width, :] = image\n",
    "    return merged_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.630687Z",
     "start_time": "2017-08-31T00:09:13.622581Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def normalize(images):\n",
    "    '''\n",
    "    Normalize the intensity values from [0, 255] into [-1, 1].\n",
    "        images: Image array to normalize. Require each intensity value\n",
    "                ranges from 0 to 255.\n",
    "    Return normalized image array.\n",
    "    '''\n",
    "    return 1.0 * np.array(images) / 255 * 2.0 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.654489Z",
     "start_time": "2017-08-31T00:09:13.632385Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def unnormalize(images):\n",
    "    '''\n",
    "    Unnormalize the intensity values from [-1, 1] to [0, 255].\n",
    "        images: Image array to unnormalize. Require each intensity value \n",
    "                ranges from -1 to 1.\n",
    "    Return unnormalized image array.\n",
    "    '''\n",
    "    return (images + 1.0) / 2.0 * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.669959Z",
     "start_time": "2017-08-31T00:09:13.656650Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gen_unnormalized_random_images(image_shape, count):\n",
    "    '''\n",
    "    Generate unnormalized image with random intensity values. Each intensity\n",
    "    value ranges from 0 to 255.\n",
    "        image_shape: Shape of an image. Format: [height, width, channels]\n",
    "        count:       Number of random images to generate.\n",
    "    Return array of generated random images.\n",
    "    '''\n",
    "    height, width, channels = image_shape\n",
    "    intermediate_images = np.random.normal(loc = 0, scale = 0.3, \n",
    "                          size = [count, height, width, channels])\n",
    "    intermediate_images = intermediate_images - intermediate_images.min()\n",
    "    return intermediate_images / intermediate_images.max() * 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.679844Z",
     "start_time": "2017-08-31T00:09:13.671450Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_image_shape(path):\n",
    "    '''\n",
    "    Get shape of image. Format: [height, width, channels]. In fact, all images\n",
    "    are regarded as color images, thus, channels is always 3.\n",
    "        path: Path of image file.\n",
    "    Return array of image shape.\n",
    "    '''\n",
    "    image = scipy.misc.imread(path)\n",
    "    [height, width, channels] = image.shape\n",
    "    return [height, width, channels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "This section loads the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.689518Z",
     "start_time": "2017-08-31T00:09:13.681462Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Root directory of data directory. Customize it when using another directory.\n",
    "# e.g. \"./\"\n",
    "data_dir_root = \"./\"\n",
    "# Path of data directory.\n",
    "data_dir_path = os.path.join(data_dir_root, \"data\")\n",
    "# Path of dataset directory.\n",
    "dataset_dir_path = os.path.join(data_dir_root, \"dataset\")\n",
    "# Path of CelebA dataset directory.\n",
    "celeba_dir_path = os.path.join(dataset_dir_path, \"celeba\")\n",
    "# Path of CelebA dataset directory for cropped images.\n",
    "celeba_cropped_dir_path = os.path.join(celeba_dir_path, \"cropped\")\n",
    "\n",
    "# Create a series of directories.\n",
    "mkdir_if_not_exists(data_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "This section focus on build the INNg model. It contains layers, discriminator and generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "This subsection contains all layers used in INNg model. E.g. convolutional layer, leaky ReLU layer, linear layer and batch normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.706333Z",
     "start_time": "2017-08-31T00:09:13.691091Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input, output_channels, scope):\n",
    "    '''\n",
    "    2-D convolutional layer.\n",
    "        input:           Input layer.\n",
    "        output_channels: Output channels.\n",
    "        scope:           Variable scope.\n",
    "    Return output of 2-D convolutional layer.\n",
    "    '''\n",
    "    \n",
    "    # Pre-defined parameters.\n",
    "    in_height = 5\n",
    "    in_width = 5 \n",
    "    in_channels = input.get_shape().as_list()[-1]\n",
    "    delta_height = 2\n",
    "    delta_width = 2 \n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        # Variable for filter.\n",
    "        filter = tf.get_variable(\n",
    "            name = 'filter', \n",
    "            shape = [in_height, in_width, in_channels, output_channels],\n",
    "            initializer = tf.truncated_normal_initializer(stddev = 0.02),\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(scale = 0.0002)\n",
    "        )\n",
    "        # Do convolution.\n",
    "        conv = tf.nn.conv2d(input, \n",
    "                            filter, \n",
    "                            strides = [1, delta_height, delta_width, 1], \n",
    "                            padding = 'SAME')\n",
    "        # Variable for bias.\n",
    "        bias = tf.get_variable(name = 'bias', \n",
    "                               shape = [output_channels], \n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "        # Add bias.\n",
    "        conv = tf.reshape(tf.nn.bias_add(conv, bias), conv.get_shape())\n",
    "\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.724340Z",
     "start_time": "2017-08-31T00:09:13.707676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(input):\n",
    "    '''\n",
    "    Leaky ReLU layer.\n",
    "        input: Input layer.\n",
    "    Return output of leaky ReLU layer.\n",
    "    '''\n",
    "    \n",
    "    # Pre-defined leak coefficient. \n",
    "    leak = 0.2\n",
    "    \n",
    "    # Do leaky ReLU and return.\n",
    "    return tf.maximum(input, leak * input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.736698Z",
     "start_time": "2017-08-31T00:09:13.725517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(input, output_size, scope):\n",
    "    '''\n",
    "    Linear layer.\n",
    "        input:       Input layer.\n",
    "        output_size: Output size.\n",
    "        scope:       Variable scope.\n",
    "    Return output of linear layer.\n",
    "    '''\n",
    "    \n",
    "    # Only consider input is 2-D, that is, shape is [batch_size, input_size].\n",
    "    shape = input.get_shape().as_list()\n",
    "    batch_size, input_size = shape\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        # Variable of matrix.\n",
    "        matrix = tf.get_variable(\n",
    "            name = \"matrix\", \n",
    "            shape = [input_size, output_size], \n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.random_normal_initializer(stddev = 0.02),\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(0.0002)\n",
    "        )\n",
    "        \n",
    "        # Variable of bias.\n",
    "        bias = tf.get_variable(name = \"bias\", \n",
    "                               shape = [output_size],\n",
    "                               initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "        # Do multiplication and return.\n",
    "        return tf.matmul(input, matrix) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.746275Z",
     "start_time": "2017-08-31T00:09:13.738007Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(input, is_training, reuse, scope):\n",
    "    '''\n",
    "    Batch normalization layer.\n",
    "        input:       Input layer.\n",
    "        is_training: True in training, False in evaluation.\n",
    "        reuse:       Reuse weights or not.\n",
    "        scope:       Variable scope.\n",
    "    Return output of batch normalization layer.\n",
    "    '''\n",
    "    return tf.contrib.layers.batch_norm(input,\n",
    "                                        decay = 0.9, \n",
    "                                        updates_collections = None,\n",
    "                                        epsilon = 1e-5,\n",
    "                                        scale = True,\n",
    "                                        is_training = is_training,\n",
    "                                        reuse = reuse,\n",
    "                                        scope = scope)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "This subsection builds the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.763371Z",
     "start_time": "2017-08-31T00:09:13.747656Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images):\n",
    "    '''\n",
    "    Build discriminator.\n",
    "        images: Training images. Shape is [batch size, height, width, channels]\n",
    "    Return the predicted outputs of sigmoid and its logits.\n",
    "    '''\n",
    "    \n",
    "    # Consider scope layers. Because we build discriminator at first, \n",
    "    # reuse shoule be False here to create variables. Later when we build\n",
    "    # generator, reuse should be True as variables have been created.\n",
    "    with tf.variable_scope(\"layers\", reuse = False):\n",
    "\n",
    "        # Pre-defined dimension of filters in first layer.\n",
    "        filter_dim = 64\n",
    "\n",
    "        # Fetch batch size from images.\n",
    "        batch_size = images.get_shape().as_list()[0]\n",
    "\n",
    "        # Hidden layer 0.\n",
    "        h0 = lrelu(conv2d(images, filter_dim, scope = 'h0_conv'))\n",
    "        \n",
    "        # Hidden layer 1.\n",
    "        h1_conv = conv2d(h0, filter_dim * 2, scope = 'h1_conv')\n",
    "        h1_bn = batch_norm(h1_conv, is_training = True,\n",
    "                           reuse = False, scope = 'h1_bn')\n",
    "        h1 = lrelu(h1_bn)\n",
    "\n",
    "        # Hidden layer 2.\n",
    "        h2_conv = conv2d(h1, filter_dim * 4, scope = 'h2_conv')\n",
    "        h2_bn = batch_norm(h2_conv, is_training = True,\n",
    "                           reuse = False, scope = 'h2_bn')\n",
    "        h2 = lrelu(h2_bn)\n",
    "\n",
    "        # Hidden layer 3.\n",
    "        h3_conv = conv2d(h2, filter_dim * 8, scope = 'h3_conv')\n",
    "        h3_bn = batch_norm(h3_conv, is_training = True, \n",
    "                           reuse = False, scope = 'h3_bn')\n",
    "        h3 = lrelu(h3_bn)\n",
    "\n",
    "        # Hidden layer 4.\n",
    "        h4 = linear(tf.reshape(h3, [batch_size, -1]), \n",
    "                    output_size = 1, scope = 'h4_linear')\n",
    "\n",
    "        return tf.nn.sigmoid(h4), h4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "This subsection builds the generator. It always reuses the values of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.779086Z",
     "start_time": "2017-08-31T00:09:13.764593Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def generator(images):  \n",
    "    '''\n",
    "    Build generator.\n",
    "        images: Training images. Shape is [batch size, height, width, channels]\n",
    "    Return the predicted outputs of sigmoid and its logits.\n",
    "    '''\n",
    "    \n",
    "    # Consider scope layers. Always reuse the variables because those variables\n",
    "    # have been created in discriminator.\n",
    "    with tf.variable_scope(\"layers\", reuse = True):\n",
    "        \n",
    "        # Pre-defined dimension of filters in first layer.\n",
    "        filter_dim = 64\n",
    "\n",
    "        # Fetch batch size from images.\n",
    "        batch_size = images.get_shape().as_list()[0]\n",
    "\n",
    "        # Hidden layer 0.\n",
    "        h0 = lrelu(conv2d(images, filter_dim, scope = 'h0_conv'))\n",
    "    \n",
    "        # Hidden layer 1.\n",
    "        h1_conv = conv2d(h0, filter_dim * 2, scope = 'h1_conv')\n",
    "        h1_bn = batch_norm(h1_conv, is_training = False,\n",
    "                           reuse = True, scope = 'h1_bn')\n",
    "        h1 = lrelu(h1_bn)\n",
    "\n",
    "        # Hidden layer 2.\n",
    "        h2_conv = conv2d(h1, filter_dim * 4, scope = 'h2_conv')\n",
    "        h2_bn = batch_norm(h2_conv, is_training = False,\n",
    "                           reuse = True, scope = 'h2_bn')\n",
    "        h2 = lrelu(h2_bn)\n",
    "\n",
    "        # Hidden layer 3.\n",
    "        h3_conv = conv2d(h2, filter_dim * 8, scope = 'h3_conv')\n",
    "        h3_bn = batch_norm(h3_conv, is_training = False, \n",
    "                           reuse = True, scope = 'h3_bn')\n",
    "        h3 = lrelu(h3_bn)\n",
    "\n",
    "        # Hidden layer 4.\n",
    "        h4 = linear(tf.reshape(h3, [batch_size, -1]), \n",
    "                    output_size = 1, scope = 'h4_linear')\n",
    "\n",
    "        return tf.nn.sigmoid(h4), h4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "This subsection builds the INNg model based on discriminator and generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.803333Z",
     "start_time": "2017-08-31T00:09:13.780409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(batch_shape):\n",
    "    '''\n",
    "    Build an INNg model as network.\n",
    "        batch_shape: Shape of a mini-batch in discriminating and generating.\n",
    "                     The format is [batch size, height, width, channels].\n",
    "    Return loss, trainable variables, labels and images in discriminator and \n",
    "    generator, plus checkpoint saver. \n",
    "    '''\n",
    "\n",
    "    # Get details of batch shape.\n",
    "    [batch_size, height, width, channels] = batch_shape\n",
    "    \n",
    "    # Placeholder of images and labels.\n",
    "    D_images = tf.placeholder(dtype = tf.float32, \n",
    "                              shape = [batch_size, height, width, channels], \n",
    "                              name = 'D_images')\n",
    "    D_labels = tf.placeholder(dtype = tf.float32, \n",
    "                              shape = [batch_size, 1], \n",
    "                              name = 'D_labels')\n",
    "\n",
    "    # Variable, placeholder and assign operator for multiple generated images.\n",
    "    G_images = tf.Variable(\n",
    "        # Use uniform distribution Unif(-1, 1) to initialize.\n",
    "        np.random.uniform(low = -1.0, \n",
    "                          high = 1.0, \n",
    "                          size = [batch_size, height, width, channels]\n",
    "        ).astype('float32'), \n",
    "        name='G_images'\n",
    "    )\n",
    "    G_images_placeholder = tf.placeholder(dtype = G_images.dtype, \n",
    "                                          shape = G_images.get_shape())\n",
    "    G_images_op = G_images.assign(G_images_placeholder)\n",
    "\n",
    "    # Build discriminator.\n",
    "    # D is sigmoid(D_logits).\n",
    "    D, D_logits = discriminator(D_images)\n",
    "    D_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits = D_logits, \n",
    "            labels = D_labels\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Build generator.\n",
    "    # G is sigmoid(G_logits).\n",
    "    G, G_logits = generator(G_images)\n",
    "    G_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits = G_logits, \n",
    "            # All labels point to positive examples, which is similar as GAN.\n",
    "            # \n",
    "            # Thus, minimize G_loss\n",
    "            #    => minimize -log(sigmoid(G_logits))\n",
    "            #    => maximize G_logits\n",
    "            #    => maximize g_t(x) in the paper\n",
    "            #    => maximize ln g_t(x) in the paper\n",
    "            labels = tf.ones_like(G_logits) * 1.0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Variables to train.\n",
    "    trainable_vars = tf.trainable_variables()\n",
    "    D_vars = [var for var in trainable_vars if 'layers' in var.name]\n",
    "    G_vars = [var for var in trainable_vars if 'G_images' in var.name]\n",
    "    \n",
    "    # Checkpoint saver.\n",
    "    saver = tf.train.Saver(max_to_keep = 5000)\n",
    "    \n",
    "    return [D_loss, G_loss, D_vars, G_vars, \n",
    "            D_images, G_images, G_images_op, G_images_placeholder,\n",
    "            D_labels, saver]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "This section focuses on model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:13.815512Z",
     "start_time": "2017-08-31T00:09:13.804801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizers(D_loss, G_loss, D_vars, G_vars):\n",
    "    '''\n",
    "    Get optimizers.\n",
    "        D_loss: Discriminator loss.\n",
    "        G_loss: Generator loss.\n",
    "        D_vars: Variables to train in discriminator.\n",
    "        G_vars: Variables to train in generator.\n",
    "    Return optimizer of discriminator and generator, plus discriminator \n",
    "    learning rate, discriminator global steps and initializer for generator.\n",
    "    '''\n",
    "    \n",
    "    # Scope of discriminator optimizer.\n",
    "    with tf.variable_scope('D_optimizer'):\n",
    "        # Learning rate.\n",
    "        D_learning_rate = 0.01\n",
    "        D_optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate = D_learning_rate).minimize(\n",
    "                loss = D_loss, var_list = D_vars)\n",
    "        \n",
    "    # Scope of generator optimizer.\n",
    "    with tf.variable_scope('G_optimizer'):\n",
    "        G_adam = tf.train.AdamOptimizer(learning_rate = 0.02, beta1 = 0.5)\n",
    "        G_optimizer = G_adam.minimize(loss = G_loss, var_list = G_vars)\n",
    "    \n",
    "    # Variables of generator optimizer and initializer operator of that.\n",
    "    G_optimizer_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \n",
    "                                         scope = 'G_optimizer')\n",
    "    G_optimizer_initializer_op = tf.variables_initializer(G_optimizer_vars)\n",
    "    \n",
    "    return [D_optimizer, G_optimizer, \n",
    "            D_learning_rate,\n",
    "            G_optimizer_initializer_op]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:09:14.247516Z",
     "start_time": "2017-08-31T00:09:13.816996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(sess):\n",
    "    \"\"\"\n",
    "    Train the INNg model.\n",
    "        sess: Session.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set timer.\n",
    "    start_time = time.time()\n",
    "    # Batch size. It should be a squared number.\n",
    "    batch_size = 100\n",
    "    half_batch_size = batch_size // 2\n",
    "    sqrt_batch_size = int(np.sqrt(batch_size))\n",
    "    # How many cascades in INNg.\n",
    "    cascades = 100\n",
    "    # How many iterations for each cascade classifier.\n",
    "    iterations_per_cascade = 100\n",
    "    # Log file path.\n",
    "    log_file_path = os.path.join(data_dir_path, \"log.txt\")\n",
    "    # Prepare for root directory of model.\n",
    "    model_root = os.path.join(data_dir_path, \"model\")\n",
    "    mkdir_if_not_exists(model_root)\n",
    "    # Prepare for root directory of intermediate image.\n",
    "    intermediate_image_root = os.path.join(data_dir_path, \"intermediate\")\n",
    "    mkdir_if_not_exists(intermediate_image_root)\n",
    "    # Prepare for root directory of negative images.\n",
    "    neg_image_root = os.path.join(data_dir_path, \"negative\")\n",
    "    mkdir_if_not_exists(neg_image_root)\n",
    "        \n",
    "    ######################################################################\n",
    "    # Training stage 1: Load positive and negative images.\n",
    "    ######################################################################\n",
    "    log(log_file_path,\n",
    "        \"Training stage 1: Load positive and negative images...\")\n",
    "    \n",
    "    def gen_neg_init_images(neg_image_root, image_shape):\n",
    "        '''\n",
    "        Generate negative initial images.\n",
    "            data_dir_path: Data directory to contain negative images directory.\n",
    "            image_shape:   Shape of image. Format: [height, width, channels]\n",
    "        Return array of generated initial images path and their root directory.\n",
    "        '''\n",
    "        # In fact, the name of image has format \n",
    "        #     {cascade}_{next iteration}_{i}.png\n",
    "        # where cascade means current cascade model, next iteration means\n",
    "        # next iteration of generator and discriminator training, and i means\n",
    "        # the index of images.\n",
    "        neg_image_path = os.path.join(neg_image_root, 'cascade_{0}_iteration_{1}_count_{2}.png')\n",
    "        neg_init_images_count = 10000\n",
    "        neg_init_images_path = [neg_image_path.format(0, 0, i) \\\n",
    "                                for i in range(neg_init_images_count)]\n",
    "       \n",
    "        # Generate random images as negatives and save them.\n",
    "        for i, neg_init_image_path in enumerate(neg_init_images_path):\n",
    "            # Attention: Though it is called neg_image here, it has 4 dimensions,\n",
    "            #            that is, [1, height, width, channels], which is not a\n",
    "            #            pure single image, which is [height, width, channels].\n",
    "            #            So we still use save_unnormalized_images here instead of \n",
    "            #            save_unnormalized_image.\n",
    "            neg_image = gen_unnormalized_random_images(\n",
    "                image_shape = image_shape, count = 1)\n",
    "            save_unnormalized_images(images = neg_image, \n",
    "                                     size = (1, 1), path = neg_init_image_path)\n",
    "            \n",
    "        return neg_init_images_path\n",
    "        \n",
    "    # Path of all positive images and negative images. \n",
    "    # The following celeba_cropped_dir_path can be replaced. The image shape of\n",
    "    # positive and negative images are the same.\n",
    "    pos_all_images_path = get_images_path_in_directory(celeba_cropped_dir_path)\n",
    "    image_shape = get_image_shape(pos_all_images_path[0])\n",
    "    neg_all_images_path = gen_neg_init_images(\n",
    "        neg_image_root = neg_image_root, \n",
    "        image_shape = image_shape)\n",
    "    log(log_file_path,\n",
    "        \"Positive images {0}, negative images {1}, image shape {2}\".format(\n",
    "        len(pos_all_images_path), len(neg_all_images_path), image_shape))\n",
    "\n",
    "    ######################################################################\n",
    "    # Training stage 2: Build network and initialize.\n",
    "    ######################################################################\n",
    "    log(log_file_path,\n",
    "        \"Training stage 2: Build network and initialize...\")\n",
    "    height, width, channels = image_shape\n",
    "    \n",
    "    # Build network.\n",
    "    [D_loss, G_loss, D_vars, G_vars, \n",
    "     D_images, G_images, G_images_op, G_images_placeholder,\n",
    "     D_labels, saver] = \\\n",
    "        build_network(batch_shape = [batch_size, height, width, channels])\n",
    "        \n",
    "    # Get optimizer.\n",
    "    [D_optimizer, G_optimizer, \n",
    "     D_learning_rate,\n",
    "     G_optimizer_initializer_op] = \\\n",
    "        get_optimizers(D_loss = D_loss, G_loss = G_loss, \n",
    "                       D_vars = D_vars, G_vars = G_vars)\n",
    "    \n",
    "    # Show a list of global variables.\n",
    "    global_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='')\n",
    "    log(log_file_path, \"Global variables:\")\n",
    "    for i, var in enumerate(global_variables):\n",
    "        log(log_file_path, \"{0} {1}\".format(i, var.name))\n",
    "        \n",
    "    # Initialize all variables.\n",
    "    all_initializer_op = tf.global_variables_initializer()\n",
    "    sess.run(all_initializer_op)\n",
    "    \n",
    "    ######################################################################\n",
    "    # Training stage 3: Cascades training.\n",
    "    ######################################################################\n",
    "    log(log_file_path, \"Training stage 3: Cascades training...\")\n",
    "    \n",
    "    # INNg single: Only one cascade with multiple iterations.\n",
    "    # INNg cascade: Multiple cascades, each cascade with one iteration.\n",
    "    # (model_cascade.py in Long Jin's code, but I have not checked it)\n",
    "    # INNg compact: Multiple cascades, each cascade with multiple iterations.\n",
    "    # (model_few.py in Long Jin's code)\n",
    "    # Here we use INNg compact model. The definition of cascade and iteration\n",
    "    # can be found below.\n",
    "    \n",
    "    # One cascade means one new model.\n",
    "    # p <- [cascade n] <- [cascade n-1] <- ... <- [cascade 0] <- p_r \n",
    "    # where p_r means Uniform or Gaussian reference distribution \n",
    "    # and p means estimated negative distribution in paper.\n",
    "    # One cascade training may contain multiple iterations.\n",
    "    \n",
    "    # Prepare for the initial images to feed the generator. In fact, it is \n",
    "    # because we always use negative images in last cascade as the \"initial\"\n",
    "    # images to feed generator in all iterations of current cascade.\n",
    "    G_neg_last_cascade_images_path = copy.deepcopy(neg_all_images_path)\n",
    "    \n",
    "    for cascade in xrange(cascades):\n",
    "        ######################################################################\n",
    "        # Training stage 3.1: Iterations training.\n",
    "        ######################################################################\n",
    "        # One iteration means one time of discriminator training and one time\n",
    "        # of generator training. One iteration training may contain multiple\n",
    "        # batches for discriminator and generator training.\n",
    "        for iteration in xrange(iterations_per_cascade):\n",
    "            ######################################################################\n",
    "            # Training stage 3.1.1: Prepare images and labels for discriminator\n",
    "            # training.\n",
    "            ######################################################################\n",
    "            # Count of positive images to train in current iteration.\n",
    "            # Still, it is a strange strategy from Long Jin's code.\n",
    "            D_pos_iteration_images_count = min(iteration + 1, 5) * 1000 \\\n",
    "                // half_batch_size * half_batch_size\n",
    "            \n",
    "            if D_pos_iteration_images_count >= len(pos_all_images_path):\n",
    "                # When the number of all positive images is more than current\n",
    "                # iteration negative images, we allow duplicate images.\n",
    "                D_pos_iteration_images_path = np.random.choice(\n",
    "                    pos_all_images_path, \n",
    "                    size = D_pos_iteration_images_count, \n",
    "                    replace = True\n",
    "                ).tolist()\n",
    "            else:\n",
    "                # When the number of all positive images is less or equal than \n",
    "                # current iteration negative images, we require unique images.\n",
    "                D_pos_iteration_images_path = np.random.choice(\n",
    "                    pos_all_images_path, \n",
    "                    size = D_pos_iteration_images_count, \n",
    "                    replace = False\n",
    "                ).tolist()\n",
    "\n",
    "            # Here we consider the \"save all\" mode in Long Jin's code. This mode\n",
    "            # has different behaviors on discriminator and generator.\n",
    "            # 1) Discriminator.\n",
    "            #     We draw positive images from all positive images and the same\n",
    "            #     number of negative images from all negative images. Every \n",
    "            #     iteration of generator will add newly generated negative images\n",
    "            #     into all negative images.\n",
    "            # 2) Generator.\n",
    "            #     We draw \"initial\" negative images in every iterations in current\n",
    "            #     cascade from part of generated negative images in last cascade.\n",
    "            #     More specificially, the part is the last iteration of last cascade.\n",
    "            #     When current cascade ends, the generated negative images will be\n",
    "            #     used in next cascade.\n",
    "            D_neg_iteration_images_count = D_pos_iteration_images_count\n",
    "            D_neg_iteration_images_path = np.random.choice(\n",
    "                neg_all_images_path,\n",
    "                D_pos_iteration_images_count, \n",
    "                replace = True).tolist()\n",
    "                \n",
    "            # Images and labels in discriminator training in current iteration.\n",
    "            D_iteration_images_path = D_pos_iteration_images_path + \\\n",
    "                                      D_neg_iteration_images_path\n",
    "            # Labels need to be reshaped into 2-D in order to match the shape\n",
    "            # of output of last linear layer in discriminator.\n",
    "            D_iteration_labels = np.array(\n",
    "                [1.0] * D_pos_iteration_images_count + \\\n",
    "                [0.0] * D_neg_iteration_images_count\n",
    "            ).reshape(-1, 1)\n",
    "            # Shuffle current iteration images with labels.\n",
    "            D_iteration_images_path, D_iteration_labels = \\\n",
    "                shuffle(D_iteration_images_path, D_iteration_labels)\n",
    "            \n",
    "            log(log_file_path,\n",
    "                   (\"Discriminator: Cascade {0}, iteration {1}, \" + \n",
    "                   \"all pos {2}, all neg {3}, \" + \n",
    "                   \"current iteration {4} (pos {5}, neg {6}), \" + \n",
    "                   \"learning rate {7}\").format(\n",
    "                       cascade, iteration, \n",
    "                       len(pos_all_images_path), len(neg_all_images_path), \n",
    "                       len(D_iteration_images_path), \n",
    "                       D_pos_iteration_images_count, D_neg_iteration_images_count, \n",
    "                       D_learning_rate\n",
    "                   ))\n",
    "            \n",
    "            ######################################################################\n",
    "            # Training stage 3.1.2: Train the discriminator.\n",
    "            ######################################################################\n",
    "            # Count of batch in discriminator training in current iteration. \n",
    "            D_iteration_count_of_batch = len(D_iteration_images_path) // batch_size\n",
    "            for i in xrange(D_iteration_count_of_batch):\n",
    "                # Load images for this batch in discriminator.\n",
    "                D_batch_images = [load_unnormalized_image(path) for path in\n",
    "                    D_iteration_images_path[i * batch_size : (i + 1) * batch_size]]\n",
    "                # Normalize.\n",
    "                D_batch_images = normalize(np.array(D_batch_images)).astype(np.float32)\n",
    "                # Read labels for this batch in discriminator.\n",
    "                D_batch_labels = D_iteration_labels[i * batch_size : (i + 1) * batch_size]\n",
    "                # Currently the decay is disabled according to Long Jin's reply.\n",
    "                sess.run(D_optimizer, \n",
    "                         feed_dict = {D_images: D_batch_images, \n",
    "                                      D_labels: D_batch_labels})\n",
    "\n",
    "            # Discriminator loss after training in current iteration.\n",
    "            D_last_batch_loss = sess.run(D_loss, \n",
    "                 feed_dict = {D_images: D_batch_images, \n",
    "                              D_labels: D_batch_labels})\n",
    "    \n",
    "            log(log_file_path, \n",
    "                \"Discriminator: Cascade {0}, iteration {1}, time {2}, D_loss {3}\".format(\n",
    "                cascade, iteration, time.time() - start_time, D_last_batch_loss))\n",
    "        \n",
    "            # Save last batch images in discriminator training.\n",
    "            D_intermediate_image_path = os.path.join(intermediate_image_root,\n",
    "                'D_cascade_{0}_iteration_{1}.png').format(cascade, iteration)\n",
    "            save_unnormalized_images(images = unnormalize(D_batch_images), \n",
    "                                     size = (sqrt_batch_size, sqrt_batch_size), \n",
    "                                     path = D_intermediate_image_path)\n",
    "        \n",
    "            ######################################################################\n",
    "            # Training stage 3.1.3: Prepare images for generator training.\n",
    "            ######################################################################\n",
    "\n",
    "            # Load path of negative images in last cascade and shuffle.\n",
    "            G_neg_last_cascade_images_path = shuffle(G_neg_last_cascade_images_path)\n",
    "            # Attention again, the last cascade here does not mean all negative images\n",
    "            # produced in last cascade, but only negative images in last iteration of\n",
    "            # last cascade.\n",
    "\n",
    "            # Count of negative images generated in current iteration.\n",
    "            # Strange strategy from Long Jin's code.\n",
    "            if iteration == iterations_per_cascade - 1:\n",
    "                # Generate more in last iteration of cascade.\n",
    "                G_neg_iteration_images_count = 10000\n",
    "            else:\n",
    "                G_neg_iteration_images_count = 1000\n",
    "            \n",
    "            G_neg_current_iteration_images_path = \\\n",
    "                [os.path.join(neg_image_root, 'cascade_{0}_iteration_{1}_count_{2}.png').format(\n",
    "                    cascade, iteration + 1, i) for i in xrange(\n",
    "                        G_neg_iteration_images_count)]\n",
    "            \n",
    "            log(log_file_path,\n",
    "                  (\"Generator: Cascade {0}, iteration {1}, \" + \n",
    "                   \"current iteration neg {2}\").format(\n",
    "                   cascade, iteration, \n",
    "                   G_neg_iteration_images_count))\n",
    "                  \n",
    "            ######################################################################\n",
    "            # Training stage 3.1.3: Train the generator.\n",
    "            ######################################################################\n",
    "            # Count of batch in generator training in current iteration. \n",
    "            G_iteration_count_of_batch = G_neg_iteration_images_count // batch_size\n",
    "            for i in xrange(G_iteration_count_of_batch):\n",
    "                # Initialize the Adam optimizer every iteration.\n",
    "                # sess.run(G_optimizer_initializer_op)\n",
    "\n",
    "                # Load images from last cascade generated negative images.\n",
    "                # We mention it again, that is, in each iteration in current cascade, \n",
    "                # we will generate images based on last cascade, but not last iteration. \n",
    "                # It is quite a strange strategy.\n",
    "                G_neg_batch_images = [load_unnormalized_image(path) for path in\n",
    "                    G_neg_last_cascade_images_path[i * batch_size : \n",
    "                                                   (i + 1) * batch_size]]\n",
    "                # Normalize.\n",
    "                G_neg_batch_images = normalize(np.array(G_neg_batch_images)\n",
    "                                              ).astype(np.float32)\n",
    "                # Feed into generator.\n",
    "                sess.run(G_images_op, {G_images_placeholder: \n",
    "                                       G_neg_batch_images})\n",
    "\n",
    "                # Generating process. We may optimize images for several times\n",
    "                # to get good images. Early stopping is used here to accelerate.\n",
    "                count_of_optimizing_steps = 2000\n",
    "                for j in range(count_of_optimizing_steps):\n",
    "                    # Optimize.\n",
    "                    sess.run(G_optimizer)\n",
    "                    # Clip and re-feed to generator.\n",
    "                    sess.run(G_images_op, feed_dict = {G_images_placeholder: \n",
    "                                                       np.clip(sess.run(G_images), -1.0, 1.0)})\n",
    "                    # Early stopping based on threshold.\n",
    "                    # The threshold is based on decision boundary of cross entropy.\n",
    "                    #     -ln(sigmoid(0)) = -ln(0.5) = ln 2 = 0.693\n",
    "                    # The boundary means it is more likely for the discriminator\n",
    "                    # to consider the images as postive.\n",
    "                    if sess.run(G_loss) <= 0.693:\n",
    "                        break\n",
    "\n",
    "                # Save intermediate negative images in generator.\n",
    "                G_neg_intermediate_images = sess.run(G_images)\n",
    "                [_, height, width, channels] = G_neg_intermediate_images.shape\n",
    "                for j in xrange(batch_size):\n",
    "                    save_unnormalized_image(\n",
    "                        image = unnormalize(G_neg_intermediate_images[j,:,:,:]),  \n",
    "                        path = G_neg_current_iteration_images_path[i * batch_size + j])\n",
    "\n",
    "                # Output information every 100 batches.\n",
    "                if i % 100 == 0:\n",
    "                    log(log_file_path,\n",
    "                          (\"Generator: Cascade {0}, iteration {1}, batch {2}, \" + \n",
    "                           \"time {3}, G_loss {4}\").format(\n",
    "                           cascade, iteration, i, \n",
    "                           time.time() - start_time, sess.run(G_loss)))\n",
    "\n",
    "            # After current iteration, new negative images will be added into all\n",
    "            # negative images. In fact, it is strange because we only add 1,000 images\n",
    "            # every iteration except last iteration, in which we add 10,000 images.\n",
    "            \n",
    "            neg_all_images_path += G_neg_current_iteration_images_path\n",
    "\n",
    "            # Save last batch images in generator training.\n",
    "            G_neg_intermediate_image_path = os.path.join(intermediate_image_root,\n",
    "                'G_cascade_{0}_iteration_{1}.png').format(cascade, iteration)\n",
    "            # In discriminator we save D_batch_images, but here we use \n",
    "            # G_intermediate_images. It is because we always use *_batch_images\n",
    "            # to represent the images we put in the discriminator or generator.\n",
    "            # So G_neg_batch_images should be the \"initial\" images in current \n",
    "            # iteration and G_neg_intermediate_images is the generated images.\n",
    "            save_unnormalized_images(images = unnormalize(G_neg_intermediate_images), \n",
    "                                     size = (sqrt_batch_size, sqrt_batch_size), \n",
    "                                     path = G_neg_intermediate_image_path)\n",
    "            \n",
    "        # Last cascade's generated negative images. More specifically, we only use\n",
    "        # those images generated by last iteration of last cascade.\n",
    "        G_neg_last_cascade_images_path = copy.deepcopy(G_neg_current_iteration_images_path)\n",
    "        \n",
    "        # Save the model.\n",
    "        saver.save(sess, (os.path.join(model_root, 'cascade-{}.model').format(cascade)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T00:12:44.138213Z",
     "start_time": "2017-08-31T00:09:14.248961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set dynamic allocation of GPU memory rather than pre-allocation.\n",
    "# Also set soft placement, which means when current GPU does not exist, \n",
    "# it will change into another.\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# Set GPU number.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# Create computation graph.\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    # Training session.\n",
    "    with tf.Session(config = config) as sess:\n",
    "        with tf.variable_scope(\"INNg\", reuse = None):\n",
    "            train(sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "221px",
    "width": "393px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
